(window.webpackJsonp=window.webpackJsonp||[]).push([[127],{498:function(e,t,n){"use strict";n.r(t);var s=n(46),o=Object(s.a)({},(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h1",{attrs:{id:"tutorial-10-using-links-to-browse-the-internet-and-wget-to-download-files"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#tutorial-10-using-links-to-browse-the-internet-and-wget-to-download-files"}},[e._v("#")]),e._v(" Tutorial 10: Using Links to browse the internet and wget to download files")]),e._v(" "),n("p",[e._v("The tardis firewall is quite restrictive to protect both tardis from the\ninternet and the internet from potentially malicious tardis users. This\nincludes restricting access to webservers directly, except some selected\nservers such as the debian mirror sites. However, tardis can also access\nthe university proxy internally, and this is what you need to use to\nbrowse the internet from inside tardis.")]),e._v(" "),n("h2",{attrs:{id:"links"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#links"}},[e._v("#")]),e._v(" Links")]),e._v(" "),n("p",[n("strong",[e._v("Links")]),e._v(" is a very good non-graphical browser. It is just like internet\nexplorer or whatever you normally use, but it runs from the console and\ndoesn't display pictures - just text, and ascii interpretations of page\nfeatures and layout. This sounds a bit limited, but you'll be amazed how\neasy it is to browse with it. It is descended from "),n("strong",[e._v("lynx")]),e._v(" which is\nalso available on tardis - the main differences are that links has a\nmenu, a download manager, supports more page features such as frames,\nand is generally more fully featured and useful. Run it now by typing\n"),n("strong",[e._v("links")]),e._v(". You will get a daunting black screen, which may initially\nmake you think it is loading - in fact this is the program. Press\n"),n("strong",[e._v("escape")]),e._v(" and a menu appears at the top of the screen. Use your arrow\nkeys to move along to "),n("strong",[e._v("Setup")]),e._v(", then down to "),n("strong",[e._v("Network Options")]),e._v('. You\nwill need to configure links to use the university http proxy. In both\nproxy fields, type in "'),n("strong",[e._v("wwwcache.cache.ed.ac.uk:3128")]),e._v('" and press\n'),n("strong",[e._v("OK")]),e._v(". You may find it surprising and very useful to know that you can\nuse your mouse in links, just by clicking in the right place in putty.\nSo you can simply click the ok button with your mouse, and navigate\nwebpages the same way. Now press "),n("strong",[e._v("g")]),e._v(" and a dialogue box will pop up.\nType in a familiar url, such as google.com - it will load very quickly,\nas there are no images! You can type things into the input boxes as\nusual, and click the buttons. There are few sites on the internet that\ncannot be browsed with links in fact. It also has an internal help\nsystem if you ever get lost. You should save your network settings so\nthe proxy is always configured when you run links - press "),n("strong",[e._v("escape")]),e._v(" to\ngo to the menu again, then "),n("strong",[e._v("setup")]),e._v(", and "),n("strong",[e._v("save options")]),e._v(". To scroll up\nand down in a long page, press "),n("strong",[e._v("^N")]),e._v(" and "),n("strong",[e._v("^P")]),e._v(". You can also go to a\nurl directly from the commandline by typing "),n("strong",[e._v("links [URL]")]),e._v(". That's\nall there is to it!")]),e._v(" "),n("h2",{attrs:{id:"wget"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#wget"}},[e._v("#")]),e._v(" WGet")]),e._v(" "),n("p",[e._v("The very handy program "),n("strong",[e._v("wget")]),e._v(" is as old as the stars but incredibly\npowerful. It is capable of retrieving files from both http and ftp, use\nproxies, download entire directories recursively, spider links and\nmirror content intelligently. You can use it to download a single file\nby using "),n("strong",[e._v("wget [full url of file]")]),e._v(", and an entire directory tree\nwith the "),n("strong",[e._v("-r")]),e._v(" option (although you should read the man page for\ncorrect usage, as there are many other flags that are needed to get\nexactly the results you want). Before you can use wget however, you have\nto make sure your environment has the proxy settings in - you can see\nyour environment by typing env. Now let's export the right settings like\nwe did previously with our EDITOR variable: '''")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[e._v("export HTTP_PROXY='http://wwwcache.cache.ed.ac.uk:3128'\nexport FTP_PROXY='http://wwwcache.cache.ed.ac.uk:3128'\n")])])]),n("p",[n("strong",[e._v('The "'),n("a",{attrs:{href:"http://",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://"),n("OutboundLink")],1),e._v('" part is important, and is usually the part people\nforget. With this in your environment wget will know to use the proxy -\nyou can disable it to get local files with')]),e._v("wget -Y off [URL]"),n("strong",[e._v('. Case\nis important here as always - that\'s an uppercase "Y". You should add\nthese two export commands to your "~/.profile" as i showed you in the\nbash tutorial. Now let\'s get a web page and look at it:')])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[e._v("wget google.com.\n")])])]),n("p",[n("strong",[e._v("We should now have a file in our current directory called index.html.\nLet's read it:")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[e._v("less index.html\n")])])]),n("p",[n("strong",[e._v("We see the raw html of the document. We can feed it to")]),e._v("links"),n("strong",[e._v("to see\nit as if it was a normal webpage:")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[e._v("links index.html\n")])])]),n("p",[n("strong",[e._v("Alternatively we can use")]),e._v("html2text"),n("strong",[e._v("to strip out the html code and\nconvert it to a regular text document:")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[e._v("html2text index.html\n")])])]),n("p",[n("strong",[e._v("This dumps the output to STDOUT, which is your screen, by default. You\ncan save this to a file by piping stdout to a file:")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[e._v("html2text index.html > tempfile.txt\n")])])]),n("p",[n("strong",[e._v("I won't discuss pipes here, but they are something you ought to know\nabout to use the shell to its full potential. I advise googling for a\nbash pipes tutorial - why not do so using links from your tardis shell!\nFinally, simply delete the two files we created:")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[e._v("rm index.html tempfile.txt\n")])])]),n("p",[e._v("''' ...and we're done. For the next tutorial you will see why wget is so\nuseful when we use it to download our first source package and compile\nit!")]),e._v(" "),n("p",[n("strong",[e._v("Next: "),n("a",{attrs:{href:"Tardis_Beginner_Tutorials/11",title:"wikilink"}},[e._v("Compiling Software from\nSource")])])])])}),[],!1,null,null,null);t.default=o.exports}}]);